{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarathM1/RAG/blob/main/RAG_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "\n",
        "Design a custom RAG pipeline to answer questions from this textbook -\n",
        "https://openstax.org/details/books/concepts-biology\n",
        "\n",
        "## Important Pointers:\n",
        "1. Download the pdf from the link above\n",
        "2. To make indexing faster, you can pick any 2 chapters from the pdf and treat it as a\n",
        "source.\n",
        "3. Use any in-memory vector database if required.\n",
        "4. Use any open source HuggingFace model as the LLM Model\n",
        "\n",
        "## Output artifacts\n",
        "1. Entire codebase in GitHub with links to access\n",
        "artifacts we need for evaluation:\n",
        "a. Please add docstrings wherever necessary.\n",
        "2. Additional Colab notebook to run the backend logic and evaluations:\n",
        "a. Please add text blocks in your Colab to add scenarios/assumptions etc to make it readable.\n",
        "3. Any additional artifacts like system design architecture, assumptions, list of issues you couldn’t solve because of time constraints and how you can fix it in future.\n",
        "\n",
        "## Additional (bonus):\n",
        "1. Streamlit/Gradio Frontend to interact with your pipeline\n",
        "2. Wrap the entire application inside a docker container\n",
        "3. Draft and implement all the necessary APIs using FastAPI or any other python web\n",
        "framework of choice\n",
        "4. Produce alternative way to do the RAG without using any library like Langchain,\n",
        "LLamaIndex or Haystack"
      ],
      "metadata": {
        "id": "CMVkVUjdvzNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM model\n",
        "Mistral 7B"
      ],
      "metadata": {
        "id": "4eJ4BlCVxAVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Dependencies"
      ],
      "metadata": {
        "id": "cvwKhg09xa12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install -U langchain_community tiktoken chromadb langchain langchainhub sentence_transformers PyMuPDF>=1.24.0"
      ],
      "metadata": {
        "id": "z2BoqhUjxcsN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMBiBxm6o0yr",
        "outputId": "4632db7d-c046-4f88-c589-5912427d79e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: PyMuPDF\n",
            "Version: 1.24.3\n",
            "Summary: A high performance Python library for data extraction, analysis, conversion & manipulation of PDF (and other) documents.\n",
            "Home-page: \n",
            "Author: Artifex\n",
            "Author-email: support@artifex.com\n",
            "License: GNU AFFERO GPL 3.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: PyMuPDFb\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz"
      ],
      "metadata": {
        "id": "XE4lG8YipK4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Ollama\n",
        "\n",
        "Ollama is a framework that allows you to run Open Source LLM models locally."
      ],
      "metadata": {
        "id": "_MD_GLK6y7fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!curl https://ollama.ai/install.sh | sh"
      ],
      "metadata": {
        "id": "Kt-TL8Cvzccv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Ollama server in the background"
      ],
      "metadata": {
        "id": "JK8bzH5ezx6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Start ollama as a backrgound process\n",
        "command = \"nohup ollama serve&\"\n",
        "\n",
        "# Use subprocess.Popen to start the process in the background\n",
        "process = subprocess.Popen(command,\n",
        "                            shell=True,\n",
        "                           stdout=subprocess.PIPE,\n",
        "                           stderr=subprocess.PIPE)\n",
        "print(\"Process ID:\", process.pid)\n",
        "time.sleep(5)  # Makes Python wait for 5 seconds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "560oQM7yz1E_",
        "outputId": "3363d440-e03a-44a5-c7fa-0b29c3b82902"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process ID: 4497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test if Ollama serve is up\n",
        "!ollama -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og3XtPRPz-TJ",
        "outputId": "5f481b93-78d1-4fb0-9e54-23e12603d1dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ollama version is 0.1.36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Pull the model\n",
        "!ollama pull mistral"
      ],
      "metadata": {
        "id": "HPLXbOZP0HiG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing the PDF Document"
      ],
      "metadata": {
        "id": "WMVEzcbz0NWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install unstructured pdf2image pdfminer.six pillow_heif PyPDF2 pytesseract pikepdf"
      ],
      "metadata": {
        "id": "va4AaqU0g_Wr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from unstructured.partition.pdf import partition_pdf\n",
        "#from unstructured.chunking.title import chunk_by_title"
      ],
      "metadata": {
        "id": "F20ggEG1gpo9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the file"
      ],
      "metadata": {
        "id": "ZI14YwvFhVM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!wget -O './data/Concepts_of_Biology.pdf' -nc 'https://assets.openstax.org/oscms-prodcms/media/documents/ConceptsofBiology-WEB.pdf?_gl=1*11bd84p*_ga*OTg3MTMyOTg1LjE3MTUyNTI1MjY.*_ga_T746F8B0QC*MTcxNTM0NTM1Ni4yLjAuMTcxNTM0NTM1Ny41OS4wLjA.'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkxu4xrtBvON",
        "outputId": "d7ec150c-fdce-42cd-b5a6-4b6984bcfa5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "File ‘./data/Concepts_of_Biology.pdf’ already there; not retrieving.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the first two chapters from PDF for easier processing"
      ],
      "metadata": {
        "id": "IkkE7KNom2M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import string\n",
        "\n",
        "import fitz"
      ],
      "metadata": {
        "id": "QbPUbZXVBaeh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(doc: fitz.Document, pages: list = None) -> str:\n",
        "    \"\"\"Process the document and return the text of its selected pages.\"\"\"\n",
        "    if isinstance(doc, str):\n",
        "        doc = fitz.open(doc)\n",
        "    SPACES = set(string.whitespace)  # used to check relevance of text pieces\n",
        "    if not pages:  # use all pages if argument not given\n",
        "        pages = range(doc.page_count)\n",
        "\n",
        "    class IdentifyHeaders:\n",
        "        \"\"\"Compute data for identifying header text.\"\"\"\n",
        "\n",
        "        def __init__(self, doc, pages: list = None, body_limit: float = None):\n",
        "            \"\"\"Read all text and make a dictionary of fontsizes.\n",
        "\n",
        "            Args:\n",
        "                pages: optional list of pages to consider\n",
        "                body_limit: consider text with larger font size as some header\n",
        "            \"\"\"\n",
        "            if pages is None:  # use all pages if omitted\n",
        "                pages = range(doc.page_count)\n",
        "            fontsizes = {}\n",
        "            for pno in pages:\n",
        "                page = doc[pno]\n",
        "                blocks = page.get_text(\"dict\", flags=fitz.TEXTFLAGS_TEXT)[\"blocks\"]\n",
        "                for span in [  # look at all non-empty horizontal spans\n",
        "                    s\n",
        "                    for b in blocks\n",
        "                    for l in b[\"lines\"]\n",
        "                    for s in l[\"spans\"]\n",
        "                    if not SPACES.issuperset(s[\"text\"])\n",
        "                ]:\n",
        "                    fontsz = round(span[\"size\"])\n",
        "                    count = fontsizes.get(fontsz, 0) + len(span[\"text\"].strip())\n",
        "                    fontsizes[fontsz] = count\n",
        "\n",
        "            # maps a fontsize to a string of multiple # header tag characters\n",
        "            self.header_id = {}\n",
        "\n",
        "            # If not provided, choose the most frequent font size as body text.\n",
        "            # If no text at all on all pages, just use 12\n",
        "            if body_limit is None:\n",
        "                temp = sorted(\n",
        "                    [(k, v) for k, v in fontsizes.items()],\n",
        "                    key=lambda i: i[1],\n",
        "                    reverse=True,\n",
        "                )\n",
        "                if temp:\n",
        "                    body_limit = temp[0][0]\n",
        "                else:\n",
        "                    body_limit = 12\n",
        "\n",
        "            sizes = sorted(\n",
        "                [f for f in fontsizes.keys() if f > body_limit], reverse=True\n",
        "            )\n",
        "\n",
        "            # make the header tag dictionary\n",
        "            for i, size in enumerate(sizes):\n",
        "                self.header_id[size] = \"#\" * (i + 1) + \" \"\n",
        "\n",
        "        def get_header_id(self, span):\n",
        "            \"\"\"Return appropriate markdown header prefix.\n",
        "\n",
        "            Given a text span from a \"dict\"/\"radict\" extraction, determine the\n",
        "            markdown header prefix string of 0 to many concatenated '#' characters.\n",
        "            \"\"\"\n",
        "            fontsize = round(span[\"size\"])  # compute fontsize\n",
        "            hdr_id = self.header_id.get(fontsize, \"\")\n",
        "            return hdr_id\n",
        "\n",
        "    def resolve_links(links, span):\n",
        "        \"\"\"Accept a span bbox and return a markdown link string.\"\"\"\n",
        "        bbox = fitz.Rect(span[\"bbox\"])  # span bbox\n",
        "        # a link should overlap at least 70% of the span\n",
        "        bbox_area = 0.7 * abs(bbox)\n",
        "        for link in links:\n",
        "            hot = link[\"from\"]  # the hot area of the link\n",
        "            if not abs(hot & bbox) >= bbox_area:\n",
        "                continue  # does not touch the bbox\n",
        "            text = f'[{span[\"text\"].strip()}]({link[\"uri\"]})'\n",
        "            return text\n",
        "\n",
        "    def write_text(page, clip, hdr_prefix):\n",
        "        \"\"\"Output the text found inside the given clip.\n",
        "\n",
        "        This is an alternative for plain text in that it outputs\n",
        "        text enriched with markdown styling.\n",
        "        The logic is capable of recognizing headers, body text, code blocks,\n",
        "        inline code, bold, italic and bold-italic styling.\n",
        "        There is also some effort for list supported (ordered / unordered) in\n",
        "        that typical characters are replaced by respective markdown characters.\n",
        "        \"\"\"\n",
        "        out_string = \"\"\n",
        "        code = False  # mode indicator: outputting code\n",
        "\n",
        "        # extract URL type links on page\n",
        "        links = [l for l in page.get_links() if l[\"kind\"] == 2]\n",
        "\n",
        "        blocks = page.get_text(\n",
        "            \"dict\",\n",
        "            clip=clip,\n",
        "            flags=fitz.TEXTFLAGS_TEXT,\n",
        "            sort=True,\n",
        "        )[\"blocks\"]\n",
        "\n",
        "        for block in blocks:  # iterate textblocks\n",
        "            previous_y = 0\n",
        "            for line in block[\"lines\"]:  # iterate lines in block\n",
        "                if line[\"dir\"][1] != 0:  # only consider horizontal lines\n",
        "                    continue\n",
        "                spans = [s for s in line[\"spans\"]]\n",
        "\n",
        "                this_y = line[\"bbox\"][3]  # current bottom coord\n",
        "\n",
        "                # check for still being on same line\n",
        "                same_line = abs(this_y - previous_y) <= 3 and previous_y > 0\n",
        "\n",
        "                if same_line and out_string.endswith(\"\\n\"):\n",
        "                    out_string = out_string[:-1]\n",
        "\n",
        "                # are all spans in line in a mono-spaced font?\n",
        "                all_mono = all([s[\"flags\"] & 8 for s in spans])\n",
        "\n",
        "                # compute text of the line\n",
        "                text = \"\".join([s[\"text\"] for s in spans])\n",
        "                if not same_line:\n",
        "                    previous_y = this_y\n",
        "                    if not out_string.endswith(\"\\n\"):\n",
        "                        out_string += \"\\n\"\n",
        "\n",
        "                if all_mono:\n",
        "                    # compute approx. distance from left - assuming a width\n",
        "                    # of 0.5*fontsize.\n",
        "                    delta = int(\n",
        "                        (spans[0][\"bbox\"][0] - block[\"bbox\"][0])\n",
        "                        / (spans[0][\"size\"] * 0.5)\n",
        "                    )\n",
        "                    if not code:  # if not already in code output  mode:\n",
        "                        out_string += \"```\"  # switch on \"code\" mode\n",
        "                        code = True\n",
        "                    if not same_line:  # new code line with left indentation\n",
        "                        out_string += \"\\n\" + \" \" * delta + text + \" \"\n",
        "                        previous_y = this_y\n",
        "                    else:  # same line, simply append\n",
        "                        out_string += text + \" \"\n",
        "                    continue  # done with this line\n",
        "\n",
        "                for i, s in enumerate(spans):  # iterate spans of the line\n",
        "                    # this line is not all-mono, so switch off \"code\" mode\n",
        "                    if code:  # still in code output mode?\n",
        "                        out_string += \"```\\n\"  # switch of code mode\n",
        "                        code = False\n",
        "                    # decode font properties\n",
        "                    mono = s[\"flags\"] & 8\n",
        "                    bold = s[\"flags\"] & 16\n",
        "                    italic = s[\"flags\"] & 2\n",
        "\n",
        "                    if mono:\n",
        "                        # this is text in some monospaced font\n",
        "                        out_string += f\"`{s['text'].strip()}` \"\n",
        "                    else:  # not a mono text\n",
        "                        # for first span, get header prefix string if present\n",
        "                        if i == 0:\n",
        "                            hdr_string = hdr_prefix.get_header_id(s)\n",
        "                        else:\n",
        "                            hdr_string = \"\"\n",
        "                        prefix = \"\"\n",
        "                        suffix = \"\"\n",
        "                        if hdr_string == \"\":\n",
        "                            if bold:\n",
        "                                prefix = \"**\"\n",
        "                                suffix += \"**\"\n",
        "                            if italic:\n",
        "                                prefix += \"_\"\n",
        "                                suffix = \"_\" + suffix\n",
        "\n",
        "                        ltext = resolve_links(links, s)\n",
        "                        if ltext:\n",
        "                            text = f\"{hdr_string}{prefix}{ltext}{suffix} \"\n",
        "                        else:\n",
        "                            text = f\"{hdr_string}{prefix}{s['text'].strip()}{suffix} \"\n",
        "                        text = (\n",
        "                            text.replace(\"<\", \"&lt;\")\n",
        "                            .replace(\">\", \"&gt;\")\n",
        "                            .replace(chr(0xF0B7), \"-\")\n",
        "                            .replace(chr(0xB7), \"-\")\n",
        "                            .replace(chr(8226), \"-\")\n",
        "                            .replace(chr(9679), \"-\")\n",
        "                        )\n",
        "                        out_string += text\n",
        "                previous_y = this_y\n",
        "                if not code:\n",
        "                    out_string += \"\\n\"\n",
        "            out_string += \"\\n\"\n",
        "        if code:\n",
        "            out_string += \"```\\n\"  # switch of code mode\n",
        "            code = False\n",
        "        return out_string.replace(\" \\n\", \"\\n\")\n",
        "\n",
        "    hdr_prefix = IdentifyHeaders(doc, pages=pages)\n",
        "    md_string = \"\"\n",
        "\n",
        "    for pno in pages:\n",
        "        page = doc[pno]\n",
        "        # 1. first locate all tables on page\n",
        "        tabs = page.find_tables()\n",
        "\n",
        "        # 2. make a list of table boundary boxes, sort by top-left corner.\n",
        "        # Must include the header bbox, which may be external.\n",
        "        tab_rects = sorted(\n",
        "            [\n",
        "                (fitz.Rect(t.bbox) | fitz.Rect(t.header.bbox), i)\n",
        "                for i, t in enumerate(tabs.tables)\n",
        "            ],\n",
        "            key=lambda r: (r[0].y0, r[0].x0),\n",
        "        )\n",
        "\n",
        "        # 3. final list of all text and table rectangles\n",
        "        text_rects = []\n",
        "        # compute rectangles outside tables and fill final rect list\n",
        "        for i, (r, idx) in enumerate(tab_rects):\n",
        "            if i == 0:  # compute rect above all tables\n",
        "                tr = page.rect\n",
        "                tr.y1 = r.y0\n",
        "                if not tr.is_empty:\n",
        "                    text_rects.append((\"text\", tr, 0))\n",
        "                text_rects.append((\"table\", r, idx))\n",
        "                continue\n",
        "            # read previous rectangle in final list: always a table!\n",
        "            _, r0, idx0 = text_rects[-1]\n",
        "\n",
        "            # check if a non-empty text rect is fitting in between tables\n",
        "            tr = page.rect\n",
        "            tr.y0 = r0.y1\n",
        "            tr.y1 = r.y0\n",
        "            if not tr.is_empty:  # empty if two tables overlap vertically!\n",
        "                text_rects.append((\"text\", tr, 0))\n",
        "\n",
        "            text_rects.append((\"table\", r, idx))\n",
        "\n",
        "            # there may also be text below all tables\n",
        "            if i == len(tab_rects) - 1:\n",
        "                tr = page.rect\n",
        "                tr.y0 = r.y1\n",
        "                if not tr.is_empty:\n",
        "                    text_rects.append((\"text\", tr, 0))\n",
        "\n",
        "        if not text_rects:  # this will happen for table-free pages\n",
        "            text_rects.append((\"text\", page.rect, 0))\n",
        "        else:\n",
        "            rtype, r, idx = text_rects[-1]\n",
        "            if rtype == \"table\":\n",
        "                tr = page.rect\n",
        "                tr.y0 = r.y1\n",
        "                if not tr.is_empty:\n",
        "                    text_rects.append((\"text\", tr, 0))\n",
        "\n",
        "        # we have all rectangles and can start outputting their contents\n",
        "        for rtype, r, idx in text_rects:\n",
        "            if rtype == \"text\":  # a text rectangle\n",
        "                md_string += write_text(page, r, hdr_prefix)  # write MD content\n",
        "                md_string += \"\\n\"\n",
        "            else:  # a table rect\n",
        "                md_string += tabs[idx].to_markdown(clean=False)\n",
        "\n",
        "        md_string += \"\\n-----\\n\\n\"\n",
        "\n",
        "    return md_string"
      ],
      "metadata": {
        "id": "vPHkZh4jjlk1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert PDF to Markdown\n",
        "- The below function extracts the tables and text from PDF along with formatting and saves it to disk\n",
        "- the file be saved in 'data' directory for later use"
      ],
      "metadata": {
        "id": "a4vR-YP7EGIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_markdown(fname, start_page, end_page):\n",
        "    \"\"\"Process the document and return the text of its selected pages.\"\"\"\n",
        "    doc = fitz.open(fname)\n",
        "    pages = []\n",
        "    pages.extend(range(start_page - 1, end_page))\n",
        "\n",
        "    # Extract text and tables from PDF and save in same directory\n",
        "    md_string = to_markdown(doc, pages)\n",
        "\n",
        "    # Save the markdown file to disk, use the same filename but change extension\n",
        "    outname = doc.name.replace(\".pdf\", \".md\")\n",
        "    pathlib.Path(outname).write_bytes(md_string.encode())"
      ],
      "metadata": {
        "id": "B7k3a-k3mMyF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use chapters 2 and 3 for processing\n",
        "\n",
        "- Please note that chapter 3 has a table which should give an example of how tables are parsed\n",
        "- Please refer the generated markdown file in data directory to see the parsed table\n",
        "- Also note that image and table headings are also parsed proparly"
      ],
      "metadata": {
        "id": "fNqj7HrPFY9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fname = './data/Concepts_of_Biology.pdf'\n",
        "start_page = 41\n",
        "end_page = 102\n",
        "\n",
        "pdf_to_markdown(fname, start_page, end_page)"
      ],
      "metadata": {
        "id": "jIkMcMx3Ekzl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use unstructured.io library for Chunking the generated Markdown file"
      ],
      "metadata": {
        "id": "A42k4rzBGNxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unstructured[md]"
      ],
      "metadata": {
        "id": "CJEc0xaRGzLZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOC_PATH = './data/Concepts_of_Biology.md'"
      ],
      "metadata": {
        "id": "cbvs9ErrGXTB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.chunking.title import chunk_by_title\n",
        "from unstructured.partition.md import partition_md\n",
        "import collections"
      ],
      "metadata": {
        "id": "RlerDIwbGwXk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elements = partition_md(filename=DOC_PATH)"
      ],
      "metadata": {
        "id": "P7Ip4HB3ncsS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"total number of elements:{len(elements)}\")\n",
        "\n",
        "categories = [el.category for el in elements]\n",
        "print(f\"Count by category:{collections.Counter(categories).most_common()}\")"
      ],
      "metadata": {
        "id": "fQVmtBVBok7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f0167e-a974-425e-e579-1ff5ea788445"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of elements:961\n",
            "Count by category:[('NarrativeText', 555), ('Title', 355), ('ListItem', 30), ('UncategorizedText', 19), ('Table', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check if tables are extracted\n",
        "- For debugging the tables are saved as text file in Table.txt\n",
        "- Each row is a single table\n",
        "- Please ignore the formatting of the table. The table is formatted proparly in the object but while writing to disk the formatting is ignored for simplicity"
      ],
      "metadata": {
        "id": "2_3-a6_wIpnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "others = [el.text for el in elements if el.category == \"Table\"]\n",
        "with open('./data/Table.txt', 'w') as f:\n",
        "    for each_txt in others:\n",
        "        f.write(each_txt)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "PP0m6gO8HYfO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check titles\n",
        "titles = [el.text for el in elements if el.category == \"Title\"]\n",
        "with open('./data/titles.txt', 'w') as f:\n",
        "    for each_title in titles:\n",
        "        f.write(each_title)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "EUQXgSz6H07J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunking by Title using Unstructured.io\n",
        "- Since unstructured has parsed the markdown file into Titles, Tables and Narrative text. It can now go ahead and chunk based on the different sections\n",
        "- In this intelligent chunking strategy the section text is kept intact and each chunk is stopped at the next section title\n",
        "- This ensures that the section text are not split between multiple chunks. Thus gives a better performance over simple chunknig strategies like RecursiveTextSplitter from langchain"
      ],
      "metadata": {
        "id": "7OEBcyaUJqOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unstructured.chunking.title import chunk_by_title"
      ],
      "metadata": {
        "id": "aZZ6TwghKLFT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_by_title(elements)\n",
        "print(len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cloBA3vyLDSt",
        "outputId": "480670f2-797f-4a1b-ec6d-a4d5d5685f83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each_chunk in chunks[:5]:\n",
        "  print(each_chunk.text)\n",
        "  metadata = each_chunk.metadata.to_dict()\n",
        "  del metadata[\"orig_elements\"]\n",
        "  print(\"\\n # Metadata\\n\")\n",
        "  print(metadata)\n",
        "  print('-'*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4gGJuEsLH3J",
        "outputId": "c4be55b3-18e0-4e3a-92ac-2adda9d2187e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER 2\n",
            "\n",
            "Chemistry of Life\n",
            "\n",
            "FIGURE 2.1 Foods such as bread, fruit, and cheese are rich sources of biological macromolecules. (credit:\n",
            "modification of work by Bengt Nyman)\n",
            "\n",
            "CHAPTER OUTLINE\n",
            "\n",
            "2.1 The Building Blocks of Molecules\n",
            "2.2 Water\n",
            "2.3 Biological Molecules\n",
            "\n",
            "INTRODUCTION\n",
            "\n",
            "The elements carbon, hydrogen, nitrogen, oxygen, sulfur, and phosphorus are\n",
            "\n",
            " # Metadata\n",
            "\n",
            "{'file_directory': './data', 'filename': 'Concepts_of_Biology.md', 'filetype': 'text/markdown', 'languages': ['eng'], 'last_modified': '2024-05-11T14:51:40'}\n",
            "------------------------------\n",
            "the key building blocks of the chemicals found in living things. They form the carbohydrates,\n",
            "nucleic acids, proteins, and lipids (all of which will be defined later in this chapter) that are the\n",
            "fundamental molecular components of all organisms. In this chapter, we will discuss these\n",
            "important building blocks and learn how the unique properties of the atoms of different elements\n",
            "affect their interactions with other atoms to form the molecules of life.\n",
            "\n",
            " # Metadata\n",
            "\n",
            "{'file_directory': './data', 'filename': 'Concepts_of_Biology.md', 'filetype': 'text/markdown', 'languages': ['eng'], 'last_modified': '2024-05-11T14:51:40'}\n",
            "------------------------------\n",
            "Food provides an organism with nutrients—the matter it needs to survive. Many of these critical\n",
            "nutrients come in the form of biological macromolecules, or large molecules necessary for life.\n",
            "These macromolecules are built from different combinations of smaller organic molecules. What\n",
            "specific types of biological macromolecules do living things require? How are these molecules\n",
            "formed? What functions do they serve? In this chapter, we will explore these questions.\n",
            "\n",
            "28 2 - Chemistry of Life\n",
            "\n",
            " # Metadata\n",
            "\n",
            "{'file_directory': './data', 'filename': 'Concepts_of_Biology.md', 'filetype': 'text/markdown', 'languages': ['eng'], 'last_modified': '2024-05-11T14:51:40'}\n",
            "------------------------------\n",
            "2.1 The Building Blocks of Molecules\n",
            "\n",
            "LEARNING OBJECTIVES\n",
            "By the end of this section, you will be able to:\n",
            "\n",
            "Describe matter and elements\n",
            "\n",
            "Describe the interrelationship between protons, neutrons, and electrons, and the ways in\n",
            "which electrons can be donated or shared between atoms\n",
            "\n",
            " # Metadata\n",
            "\n",
            "{'file_directory': './data', 'filename': 'Concepts_of_Biology.md', 'filetype': 'text/markdown', 'languages': ['eng'], 'last_modified': '2024-05-11T14:51:40'}\n",
            "------------------------------\n",
            "At its most fundamental level, life is made up of matter. Matter occupies space and has mass. All\n",
            "matter is composed of elements , substances that cannot be broken down or transformed\n",
            "chemically into other substances. Each element is made of atoms, each with a constant number of\n",
            "protons and unique properties. A total of 118 elements have been defined; however, only 92 occur\n",
            "naturally, and fewer than 30 are found in living cells. The remaining 26 elements are unstable and,\n",
            "\n",
            " # Metadata\n",
            "\n",
            "{'file_directory': './data', 'filename': 'Concepts_of_Biology.md', 'filetype': 'text/markdown', 'languages': ['eng'], 'last_modified': '2024-05-11T14:51:40'}\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert the parsed chunks to 'Document' format\n",
        "- Before indexing the data into Chroma db it must be converted to a compatible format: List of Document\n",
        "- While indexing the data we also add metadata which can be useful later for filtering the results. For example using the 'last_modeified' value we can decide to retrieve only the latest results"
      ],
      "metadata": {
        "id": "Tx9u7QEcPsK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = []\n",
        "for each_chunk in chunks:\n",
        "    metadata = each_chunk.metadata.to_dict()\n",
        "    del metadata[\"languages\"]\n",
        "    del metadata[\"orig_elements\"]\n",
        "    metadata[\"source\"] = metadata[\"filename\"]\n",
        "    documents.append(Document(page_content=each_chunk.text, metadata=metadata))"
      ],
      "metadata": {
        "id": "pNWreLEjRe_I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index the data into in-memory Vectore Database\n",
        "- The next step is to index the parsed data into vector database for later use in information retrieval step of RAG pipeline\n",
        "- For indexing the data we use **all-MiniLM-L6-v2** from sentence transformers. This embedding model maps sentences & paragraphs to a *384 dimensional dense vector space*\n",
        "- We use Chroma as our vector **database**"
      ],
      "metadata": {
        "id": "0d2s7nYXSM3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5o337rHSiJC",
        "outputId": "84d6864e-f72d-4994-fd32-f9934c399864"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "vectordb_fname = './data/chroma_db'\n",
        "vectorstore = Chroma.from_documents(documents, embeddings, persist_directory=vectordb_fname)"
      ],
      "metadata": {
        "id": "RybBrRB0Slg-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test if the information retrieval works\n",
        "- Use a sample query to retrieve similar documents from the vector database\n",
        "- *test_retrieval* is a helper function to retrieve documents from vectorstore using cosine similarity as a matching criteria"
      ],
      "metadata": {
        "id": "VSXQI9LXS0Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_retrieval(query):\n",
        "    # retrieve context - top 5 most relevant (closests) chunks to the query vector\n",
        "    # (by default Langchain is using cosine distance metric)\n",
        "    docs_chroma = vectorstore.similarity_search_with_score(query, k=5)\n",
        "\n",
        "    if docs_chroma:\n",
        "        # generate an answer based on given user query and retrieved context information\n",
        "        context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])\n",
        "\n",
        "        print(context_text)\n",
        "    else:\n",
        "        print(\"No results found!\")"
      ],
      "metadata": {
        "id": "85WetcdmTH1F"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_retrieval(query=\"define Covalent Bonds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcQz5IdqUDg7",
        "outputId": "b727b43c-fc34-4fe8-d094-c2d8788f2588"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covalent Bonds\n",
            "Another type of strong chemical bond between two or more atoms is a covalent bond . These bonds form when an\n",
            "electron is shared between two elements and are the strongest and most common form of chemical bond in living\n",
            "organisms. Covalent bonds form between the elements that make up the biological molecules in our cells. Unlike\n",
            "\n",
            "Access for free at openstax.org\n",
            "\n",
            "2.1 - The Building Blocks of Molecules 33\n",
            "\n",
            "ionic bonds, covalent bonds do not dissociate in water.\n",
            "\n",
            "Covalent Bonds\n",
            "Another type of strong chemical bond between two or more atoms is a covalent bond . These bonds form when an\n",
            "electron is shared between two elements and are the strongest and most common form of chemical bond in living\n",
            "organisms. Covalent bonds form between the elements that make up the biological molecules in our cells. Unlike\n",
            "\n",
            "Access for free at openstax.org\n",
            "\n",
            "2.1 - The Building Blocks of Molecules 33\n",
            "\n",
            "ionic bonds, covalent bonds do not dissociate in water.\n",
            "\n",
            "There are two types of covalent bonds: polar and nonpolar. Nonpolar covalent bonds form between two atoms of\n",
            "the same element or between different elements that share the electrons equally. For example, an oxygen atom can\n",
            "bond with another oxygen atom to fill their outer shells. This association is nonpolar because the electrons will be\n",
            "equally distributed between each oxygen atom. Two covalent bonds form between the two oxygen atoms because\n",
            "\n",
            "There are two types of covalent bonds: polar and nonpolar. Nonpolar covalent bonds form between two atoms of\n",
            "the same element or between different elements that share the electrons equally. For example, an oxygen atom can\n",
            "bond with another oxygen atom to fill their outer shells. This association is nonpolar because the electrons will be\n",
            "equally distributed between each oxygen atom. Two covalent bonds form between the two oxygen atoms because\n",
            "\n",
            "atoms, each atom providing one. These elements all share the electrons equally, creating four nonpolar covalent\n",
            "bonds ( Figure 2.6 ).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Pipeline"
      ],
      "metadata": {
        "id": "hX_SojFzUUMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "T4cOWRYfYhGY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "# Prompt\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Local LLM\n",
        "ollama_llm = \"mistral:latest\"\n",
        "model_local = ChatOllama(model=ollama_llm)\n",
        "\n",
        "# Chain\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model_local\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "BB_z-_I2Ymh2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"define Covalent Bonds\")"
      ],
      "metadata": {
        "id": "lRpGTqSZYqUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "5bda9555-2d09-4fb7-f915-a57675f60b65"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Covalent bonds are a type of strong chemical bond between two or more atoms that forms when an electron is shared between the elements. They are the strongest and most common form of chemical bonds in living organisms and play a crucial role in the formation of biological molecules within our cells. Unlike ionic bonds, covalent bonds do not dissociate in water. Covalent bonds can be further classified into polar and nonpolar based on the distribution of electrons between atoms. In nonpolar covalent bonds, atoms of the same element or different elements that share electrons equally form the bond, resulting in an equal distribution of electrons. For example, two oxygen atoms forming a covalent bond to fill their outer shells is a nonpolar association.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama list"
      ],
      "metadata": {
        "id": "-1W1vA2iYwyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9babc9c-5ec5-4b1c-9d92-12f077942059"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME          \tID          \tSIZE  \tMODIFIED       \n",
            "mistral:latest\t61e88e884507\t4.1 GB\t53 seconds ago\t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke(\"How does pH determine whether the solution is acidic or basic\")"
      ],
      "metadata": {
        "id": "zu-SSFAvY0TL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ce5c1620-ceb3-4f80-c240-c48c2b3f4f5a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The pH value of a solution determines its acidity or basicity by measuring the concentration of hydrogen ions (H+) in the solution. A solution with a high concentration of hydrogen ions is considered acidic and has a low pH value, while a solution with a high concentration of hydroxide ions (OH-) is basic and has a high pH value. The pH scale ranges from 0 to 14, with a neutral pH being 7. Solutions that moderate pH changes when an acid or base is added are called buffers and are important in biological systems due to their ability to maintain stable pH levels.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install gradio"
      ],
      "metadata": {
        "id": "JF7bbLBXZiJp",
        "collapsed": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_func(message, history):\n",
        "  return chain.invoke(message)"
      ],
      "metadata": {
        "id": "CAne1h3Ir9EB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "gradio_interface = gr.ChatInterface(\n",
        "        gradio_func,\n",
        "        chatbot=gr.Chatbot(),\n",
        "        textbox=gr.Textbox(placeholder=\"Example: What is a covalent bond?\", container=False, scale=7),\n",
        "        title=\"The Ollama test chatbot\",\n",
        "        description=f\"Ask the Mistral chatbot a question!\",\n",
        "        theme='gradio/base', # themes at https://huggingface.co/spaces/gradio/theme-gallery\n",
        "        retry_btn=None,\n",
        "        undo_btn=\"Delete Previous\",\n",
        "        clear_btn=\"Clear\",\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Y8m1s5VVrHxa"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradio_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "63PtfMOqq_fE",
        "outputId": "89e05247-0646-49ab-dc50-26d43ca3e45f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e26a53700d836a712c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e26a53700d836a712c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R8NYo01jJjqY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}